@article{lxinghan_2024_weblinx,
  author = {Lù, Xing Han and Kasner, Zdeněk and Reddy, Siva},
  month = {02},
  publisher = {Cornell University},
  title = {WebLINX: Real-World Website Navigation with Multi-Turn Dialogue},
  doi = {10.48550/arxiv.2402.05930},
  urldate = {2024-03-11},
  year = {2024},
  journal = {arXiv (Cornell University)}
}

@article{xia_2023_sheared_llama,
  author = {Xia, Mengzhou and Gao, Tianyu and Zeng, Zhiyuan and Chen, Danqi},
  month = {10},
  publisher = {Cornell University},
  title = {Sheared LLaMA: Accelerating Language Model Pre-training via Structured
  Pruning},
  doi = {10.48550/arxiv.2310.06694},
  urldate = {2024-03-11},
  year = {2023},
  journal = {arXiv (Cornell University)}
}

@misc{touvron_2023_llama_2,
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  month = {07},
  title = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  doi = {10.48550/arXiv.2307.09288},
  url = {https://arxiv.org/abs/2307.09288},
  year = {2023},
  organization = {arXiv.org}
}

@misc{Evaluating_Very_Long_Term_Conversational_Memory,
  author = {Maharana, Adyasha and Lee, Dong-Ho and Tulyakov, Sergey and Bansal, Mohit and Barbieri, Francesco and Fang, Yuwei},
  title = {Evaluating Very Long-Term Conversational Memory of LLM Agents},
  url = {https://arxiv.org/pdf/2402.17753.pdf},
  urldate = {2024-04-21}
}

@article{hatalis_2023_memory_matters,
  author = {Hatalis, Kostas and Christou, Despina and Myers, Joshua and Jones, Steven and Lambert, Keith and Amos-Binks, Adam and Dannenhauer, Zohreh and Dannenhauer, Dustin},
  pages = {277–280},
  title = {Memory Matters: The Need to Improve Long-Term Memory in LLM-Agents},
  doi = {10.1609/aaaiss.v2i1.27688},
  url = {https://ojs.aaai.org/index.php/AAAI-SS/article/view/27688/27461},
  urldate = {2024-04-21},
  volume = {2},
  year = {2023},
  journal = {Proceedings of the AAAI Symposium Series}
}

@misc{wei_2023_chain_of_thought_prompting,
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi Quoc, Ed and Le, V and Zhou, Denny},
  month = {01},
  title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models Chain-of-Thought Prompting},
  url = {https://arxiv.org/pdf/2201.11903.pdf},
  year = {2023}
}

@article{Large_Language_Models_Zero_Shot_Reasoners,
  author = {Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  month = {05},
  title = {Large Language Models are Zero-Shot Reasoners},
  url = {https://arxiv.org/abs/2205.11916},
  year = {2022},
  journal = {arXiv:2205.11916 [cs]}
}

@article{zheng_2024_gpt4vision,
  author = {Zheng, Boyuan and Gou, B and Kil, Jihyung and Sun, Hongjian and Su, Yu},
  month = {01},
  publisher = {Cornell University},
  title = {GPT-4V(ision) is a Generalist Web Agent, if Grounded},
  doi = {10.48550/arxiv.2401.01614},
  urldate = {2024-01-18},
  year = {2024},
  journal = {arXiv (Cornell University)}
}

@misc{zhang_2023_mind_the_gap_between_conversations_for_improved,
  author = {Zhang, Qiang and Naradowsky, Jason and Miyao, Yusuke},
  pages = {10735-10762},
  title = {Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation},
  url = {https://aclanthology.org/2023.findings-emnlp.720.pdf},
  urldate = {2024-04-21},
  year = {2023}
}

@misc{gao_retrieval_augmented_generation,
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  title = {Retrieval-Augmented Generation for Large Language Models: A Survey},
  url = {https://arxiv.org/pdf/2312.10997.pdf}
}

@misc{mccoy_right_for_wrong_reasons_diagnosing_syntactic_heuristics_natural_language_inference,
  author = {Mccoy, R and Pavlick, Ellie and Linzen, Tal},
  title = {Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference},
  url = {https://arxiv.org/pdf/1902.01007.pdf}
}

@article{reynolds_2021_beyond_the_few_shot_paradigm,
  author = {Reynolds, Laria and McDonell, Kyle},
  month = {05},
  title = {Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm},
  doi = {10.1145/3411763.3451760},
  year = {2021},
  journal = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems}
}

@misc{radford_2018_language_models_unsupervised_multitask_learners,
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  title = {Language Models are Unsupervised Multitask Learners},
  url = {https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf},
  year = {2018}
}

@article{scaling_language_models_methods_analysis_insights_from_training_gopher,
  author = {Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah B and Ring, Roman and Young, Susannah and Rutherford, Eliza and Hennigan, Tom and Menick, Jacob and Albin Cassirer and Powell, Richard J and , George and Lisa Anne Hendricks and Rauh, Maribeth and Huang, Po-Sen and Glaese, Amelia and Johannes Welbl and Sumanth Dathathri and Huang, Saffron and Uesato, Jonathan and Mellor, John W and Higgins, Irina and Creswell, Antonia and McAleese, Nat and Wu, Amy and Elsen, Erich and Jayakumar, Siddhant M and Buchatskaya, Elena and Budden, David and Sutherland, Esme and Simonyan, Karen and Paganini, M and Sifre, Laurent and Martens, Lena and Xiang Lorraine Li and Adhiguna Kuncoro and Nematzadeh, Aida and Gribovskaya, Elena and Donato, Domenic and Angeliki Lazaridou and Arthur, Michel and Jean-Baptiste Lespiau and Tsimpoukelli, Maria and Nikolai Grigorev and Fritz, Doug and Thibault Sottiaux and Mantas Pajarskas and Pohlen, Toby and Gong, Zhongying and Toyama, Daniel and Cyprien,  and Li, Yujia and Terzi, Tayfun and Mikulik, Vladimir and I. Babuschkin and Clark, Aidan and , Diego and Guy, Aurelia and Jones, Chris and Bradbury, James T and Johnson, Matthew S and Hechtman, Blake A and Weidinger, Laura and Gabriel, Iason and Isaac, William M and Lockhart, Ed and Osindero, Simon and Rimell, Laura and Dyer, Chris and Oriol Vinyals and Ayoub, Kareem and Stanway, Jeff and Bennett, Lorrayne and Demis Hassabis and Koray Kavukcuoglu and Irving, Geoffrey},
  month = {12},
  title = {Scaling Language Models: Methods, Analysis & Insights from Training
  Gopher},
  doi = {10.48550/arxiv.2112.11446},
  urldate = {2023-07-28},
  year = {2021},
  journal = {}
}

@article{liu_2022_pretrain_systematic_survey_of_prompting_methods_natural_language_processing,
  author = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  month = {09},
  title = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  doi = {10.1145/3560815},
  url = {https://arxiv.org/pdf/2107.13586.pdf},
  volume = {55},
  year = {2022},
  journal = {ACM Computing Surveys}
}

@article{wei_2022_chain_of_thought_prompting_elicits_reasoning_large_language_models,
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  month = {10},
  title = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  url = {https://arxiv.org/abs/2201.11903},
  year = {2022},
  journal = {arXiv:2201.11903 [cs]}
}

@article{self_consistency_improves_chain_thought_reasoning_language_models,
  author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  month = {10},
  title = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  url = {https://arxiv.org/abs/2203.11171},
  year = {2022},
  journal = {arXiv:2203.11171 [cs]}
}

@article{chowdhery_2022_palm_scaling_language_modeling_pathways,
  author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  month = {04},
  title = {PaLM: Scaling Language Modeling with Pathways},
  url = {https://arxiv.org/abs/2204.02311},
  year = {2022},
  journal = {arXiv:2204.02311 [cs]}
}

@misc{mu_2023_embodied_gpt,
  author = {Mu, Yao and Zhang, Qinglong and Hu, Mengkang and Wang, Wenhai and Ding, Mingyu and Jin, Jun and Wang, Bin and Dai, Jifeng and Qiao, Yu and Luo, Ping},
  month = {09},
  title = {EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought},
  doi = {10.48550/arXiv.2305.15021},
  url = {https://arxiv.org/abs/2305.15021},
  year = {2023},
  organization = {arXiv.org}
}

@misc{rake-nltk,
  author = {Sharma, Vishwas B.},
  title = {rake-nltk: Python implementation of the Rapid Automatic Keyword Extraction algorithm using NLTK},
  url = {https://pypi.org/project/rake-nltk/},
  organization = {PyPI}
}

@article{wei_2023_larger_language_models_do_in_context_learning_differently,
  author = {Wei, Jerry and Wei, Jason and Tay, Yi and Tran, Dustin and Webson, Albert and Lu, Yifeng and Chen, Xinyun and Liu, Hanxiao and Huang, Da and Zhou, Denny and Ma, Tengyu},
  month = {03},
  title = {Larger language models do in-context learning differently},
  url = {https://arxiv.org/abs/2303.03846},
  year = {2023},
  journal = {arXiv:2303.03846 [cs]}
}




@inproceedings{xu-etal-2022-beyond_goldfish_memory_long_term_open_domain_conversation,
    title = "Beyond Goldfish Memory: Long-Term Open-Domain Conversation",
    author = "Xu, Jing  and
      Szlam, Arthur  and
      Weston, Jason",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.356",
    doi = "10.18653/v1/2022.acl-long.356",
    pages = "5180--5197",
    abstract = "Despite recent improvements in open-domain dialogue models, state of the art models are trained and evaluated on short conversations with little context. In contrast, the long-term conversation setting has hardly been studied. In this work we collect and release a human-human dataset consisting of multiple chat sessions whereby the speaking partners learn about each other{'}s interests and discuss the things they have learnt from past sessions. We show how existing models trained on existing datasets perform poorly in this long-term conversation setting in both automatic and human evaluations, and we study long-context models that can perform much better. In particular, we find retrieval-augmented methods and methods with an ability to summarize and recall previous conversations outperform the standard encoder-decoder architectures currently considered state of the art.",
}



@inproceedings{jang-etal-2023_conversation_chronicles,
    title = "Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations",
    author = "Jang, Jihyoung  and
      Boo, Minseong  and
      Kim, Hyounghun",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.838",
    doi = "10.18653/v1/2023.emnlp-main.838",
    pages = "13584--13606",
    abstract = "In the field of natural language processing, open-domain chatbots have emerged as an important research topic. However, a major limitation of existing open-domain chatbot research is its singular focus on short single-session dialogue, neglecting the potential need for understanding contextual information in multiple consecutive sessions that precede an ongoing dialogue. Among the elements that compose the context in multi-session conversation settings, the time intervals between sessions and the relationships between speakers would be particularly important. Despite their importance, current research efforts have not sufficiently addressed these dialogical components. In this paper, we introduce a new 1M multi-session dialogue dataset, called Conversation Chronicles, for implementing a long-term conversation setup in which time intervals and fine-grained speaker relationships are incorporated. Following recent works, we exploit a large language model to produce the data. The extensive human evaluation shows that dialogue episodes in Conversation Chronicles reflect those properties while maintaining coherent and consistent interactions across all the sessions. We also propose a dialogue model, called ReBot, which consists of chronological summarization and dialogue generation modules using only around 630M parameters. When trained on Conversation Chronicles, ReBot demonstrates long-term context understanding with a high human engagement score.",
}






@inproceedings{niven-kao-2019-probing_neural_network_comprehension_natural_language_arguments,
    title = "Probing Neural Network Comprehension of Natural Language Arguments",
    author = "Niven, Timothy  and
      Kao, Hung-Yu",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1459",
    doi = "10.18653/v1/P19-1459",
    pages = "4658--4664",
    abstract = "We are surprised to find that BERT{'}s peak performance of 77{\%} on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.",
}




@inproceedings{gururangan-etal-2018-annotation_artifacts_natural_language_inference_data,
    title = "Annotation Artifacts in Natural Language Inference Data",
    author = "Gururangan, Suchin  and
      Swayamdipta, Swabha  and
      Levy, Omer  and
      Schwartz, Roy  and
      Bowman, Samuel  and
      Smith, Noah A.",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2017",
    doi = "10.18653/v1/N18-2017",
    pages = "107--112",
    abstract = "Large-scale datasets for natural language inference are created by presenting crowd workers with a sentence (premise), and asking them to generate three new sentences (hypotheses) that it entails, contradicts, or is logically neutral with respect to. We show that, in a significant portion of such data, this protocol leaves clues that make it possible to identify the label by looking only at the hypothesis, without observing the premise. Specifically, we show that a simple text categorization model can correctly classify the hypothesis alone in about 67{\%} of SNLI (Bowman et. al, 2015) and 53{\%} of MultiNLI (Williams et. al, 2017). Our analysis reveals that specific linguistic phenomena such as negation and vagueness are highly correlated with certain inference classes. Our findings suggest that the success of natural language inference models to date has been overestimated, and that the task remains a hard open problem.",
}







@inproceedings{language_models_are_few_shot_learners,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}





@article{deepspeed,
  author       = {Shaden Smith and
                  Mostofa Patwary and
                  Brandon Norick and
                  Patrick LeGresley and
                  Samyam Rajbhandari and
                  Jared Casper and
                  Zhun Liu and
                  Shrimai Prabhumoye and
                  George Zerveas and
                  Vijay Korthikanti and
                  Elton Zheng and
                  Rewon Child and
                  Reza Yazdani Aminabadi and
                  Julie Bernauer and
                  Xia Song and
                  Mohammad Shoeybi and
                  Yuxiong He and
                  Michael Houston and
                  Saurabh Tiwary and
                  Bryan Catanzaro},
  title        = {Using DeepSpeed and Megatron to Train Megatron-Turing {NLG} 530B,
                  {A} Large-Scale Generative Language Model},
  journal      = {CoRR},
  volume       = {abs/2201.11990},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.11990},
  eprinttype    = {arXiv},
  eprint       = {2201.11990},
  timestamp    = {Wed, 02 Feb 2022 15:00:01 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-11990.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{rajani-etal-2019-explain-yourself,
    title = "Explain Yourself! Leveraging Language Models for Commonsense Reasoning",
    author = "Rajani, Nazneen Fatema  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1487",
    doi = "10.18653/v1/P19-1487",
    pages = "4932--4942",
    abstract = "Deep learning models perform poorly on tasks that require commonsense reasoning, which often necessitates some form of world-knowledge or reasoning over information not immediately present in the input. We collect human explanations for commonsense reasoning in the form of natural language sequences and highlighted annotations in a new dataset called Common Sense Explanations (CoS-E). We use CoS-E to train language models to automatically generate explanations that can be used during training and inference in a novel Commonsense Auto-Generated Explanation (CAGE) framework. CAGE improves the state-of-the-art by 10{\%} on the challenging CommonsenseQA task. We further study commonsense reasoning in DNNs using both human and auto-generated explanations including transfer to out-of-domain tasks. Empirical results indicate that we can effectively leverage language models for commonsense reasoning.",
}



@article{Verifier_Solve_Math_Word_Problems,
  author       = {Karl Cobbe and
                  Vineet Kosaraju and
                  Mohammad Bavarian and
                  Mark Chen and
                  Heewoo Jun and
                  Lukasz Kaiser and
                  Matthias Plappert and
                  Jerry Tworek and
                  Jacob Hilton and
                  Reiichiro Nakano and
                  Christopher Hesse and
                  John Schulman},
  title        = {Training Verifiers to Solve Math Word Problems},
  journal      = {CoRR},
  volume       = {abs/2110.14168},
  year         = {2021},
  url          = {https://arxiv.org/abs/2110.14168},
  eprinttype    = {arXiv},
  eprint       = {2110.14168},
  timestamp    = {Mon, 12 Jun 2023 08:23:44 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2110-14168.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}





@misc{Bootstrapping_Reasoning_Reasoning,
      title={STaR: Bootstrapping Reasoning With Reasoning}, 
      author={Eric Zelikman and Yuhuai Wu and Jesse Mu and Noah D. Goodman},
      year={2022},
      eprint={2203.14465},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}




@article{Scratchpads_Intermediate_Computation_Language_Models,
  author       = {Maxwell I. Nye and
                  Anders Johan Andreassen and
                  Guy Gur{-}Ari and
                  Henryk Michalewski and
                  Jacob Austin and
                  David Bieber and
                  David Dohan and
                  Aitor Lewkowycz and
                  Maarten Bosma and
                  David Luan and
                  Charles Sutton and
                  Augustus Odena},
  title        = {Show Your Work: Scratchpads for Intermediate Computation with Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2112.00114},
  year         = {2021},
  url          = {https://arxiv.org/abs/2112.00114},
  eprinttype    = {arXiv},
  eprint       = {2112.00114},
  timestamp    = {Fri, 29 Apr 2022 17:42:58 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2112-00114.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}



@misc{flant5,
      title={Scaling Instruction-Finetuned Language Models}, 
      author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
      year={2022},
      eprint={2210.11416},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{minilm,
 author = {Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {5776--5788},
 publisher = {Curran Associates, Inc.},
 title = {MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {33},
 year = {2020}
}
