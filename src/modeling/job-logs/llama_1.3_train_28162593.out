
Lmod is automatically replacing "intel/2020.1.217" with "gcc/9.3.0".

DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=train
[2024-04-01 08:47:19,745][root][INFO] - project_dir: ${oc.env:WEBLINX_PROJECT_DIR}
seed: 123
project_name: llama_ft
data:
  num_proc: 8
  split_path: ${project_dir}/wl_data/splits.json
  base_dir: ${project_dir}/wl_data/demonstrations/
train:
  split: train
  num_epochs: 3
  learning_rate: 5.0e-05
  batch_size_per_device: 4
  gradient_accumulation_steps: 4
  dataloader_num_workers: 8
  gradient_checkpointing: true
  use_accelerator_device_map: false
  use_auto_device_map: true
  warmup_ratio: 0
  scheduler: linear
  optim: adamw_torch
eval:
  split: valid
  batch_size_per_device: 8
  result_dir: ${project_dir}/results/${project_name}/${eval.split}/${model.name}
  load_from_save_dir: true
model:
  name: princeton-nlp/Sheared-LLaMA-1.3B
  tokenizer: ${model.name}
  template_tokenizer: ${model.tokenizer}
  max_inp_len: null
  max_out_len: 256
  use_rope: true
  use_flash_attention_2: false
  save_dir: ${project_dir}/checkpoints/${project_name}/${model.name}
candidates:
  k: 10
  model: McGill-NLP/MiniLM-L6-dmr
  project_name: dmr
  split: ${eval.split}
  train_path: ${project_dir}/wl_data/candidates/train.jsonl
  path: ${project_dir}/wl_data/candidates/${candidates.split}.jsonl

Loading candidates: 0it [00:00, ?it/s]Loading candidates: 2it [00:00, 12282.00it/s]
[2024-04-01 08:47:25,685][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Processing demos into input records:   0%|          | 0/1 [00:00<?, ?it/s]Processing demos into input records:   0%|          | 0/1 [00:00<?, ?it/s]
Error executing job with overrides: ['+variant=ft_1.3b']
Traceback (most recent call last):
  File "/scratch/kapmcgil/weblinx/modeling/llama/train.py", line 73, in main
    selected_turns = select_turns_and_candidates_for_prompts(
  File "/home/kapmcgil/.local/lib/python3.10/site-packages/weblinx/processing/prompt.py", line 649, in select_turns_and_candidates_for_prompts
    replay = Replay.from_demonstration(demo)
  File "/home/kapmcgil/.local/lib/python3.10/site-packages/weblinx/__init__.py", line 1093, in from_demonstration
    replay = demonstration.replay
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/functools.py", line 981, in __get__
    val = self.func(instance)
  File "/home/kapmcgil/.local/lib/python3.10/site-packages/weblinx/__init__.py", line 98, in replay
    return self.load_json("replay.json")
  File "/home/kapmcgil/.local/lib/python3.10/site-packages/weblinx/__init__.py", line 165, in load_json
    if not self.has_file(filename):
  File "/home/kapmcgil/.local/lib/python3.10/site-packages/weblinx/__init__.py", line 118, in has_file
    return Path(self.path, filename).exists()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/pathlib.py", line 1288, in exists
    self.stat()
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/pathlib.py", line 1095, in stat
    return self._accessor.stat(self, follow_symlinks=follow_symlinks)
PermissionError: [Errno 13] Permission denied: '/home/kapmcgil/scratch/weblinx/modeling/wl_data/demonstrations/cptbbef/replay.json'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
